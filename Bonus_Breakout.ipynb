{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the game environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: BreakoutDeterministic-v4\n",
      "[2017-11-30 02:33:35,949] Making new env: BreakoutDeterministic-v4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(gym.envs.registry.all())\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "observation = env.reset() # This gets us the image\n",
    "print (observation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_close',\n",
       " '_closed',\n",
       " '_elapsed_seconds',\n",
       " '_elapsed_steps',\n",
       " '_ensure_no_double_wrap',\n",
       " '_env_closer_id',\n",
       " '_episode_started_at',\n",
       " '_max_episode_seconds',\n",
       " '_max_episode_steps',\n",
       " '_owns_render',\n",
       " '_past_limit',\n",
       " '_render',\n",
       " '_reset',\n",
       " '_seed',\n",
       " '_spec',\n",
       " '_step',\n",
       " 'action_space',\n",
       " 'class_name',\n",
       " 'close',\n",
       " 'configure',\n",
       " 'env',\n",
       " 'metadata',\n",
       " 'observation_space',\n",
       " 'render',\n",
       " 'reset',\n",
       " 'reward_range',\n",
       " 'seed',\n",
       " 'spec',\n",
       " 'step',\n",
       " 'unwrapped']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame, reward, is_done, _ = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "print (frame.shape, frame.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3a5ce10da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nITJL+j+3QFvlMGmcOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a5f39f978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_grayscale(img):\n",
    "    return np.dot(img[...,:3], [0.299, 0.587, 0.114]).astype(np.uint8)\n",
    "\n",
    "def crop(img,cropx=None,cropy=None):\n",
    "    y,x,c = img.shape\n",
    "    if (cropx is None) :\n",
    "        cropx = min(y, x)\n",
    "    if (cropy is None) :\n",
    "        cropy = min(y, x)\n",
    "    startx = x//2 - cropx//2\n",
    "    starty = y - cropy    \n",
    "    return img[starty:starty+cropy, startx:startx+cropx, :]\n",
    "\n",
    "def preprocess(img):\n",
    "    return np.expand_dims(imresize(to_grayscale(crop(img))/127.5-1, (84, 84), 'cubic', 'F'), axis=2)\n",
    "#     return imresize(crop(img), (84, 84), 'cubic', 'RGB')/127.5 -1\n",
    "\n",
    "def transform_reward(reward):\n",
    "        return np.sign(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0 40.8046031746\n",
      "(84, 84, 1) float32 0.169641 -1.064 -0.705634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3a5cd3a588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZgn6fwuc9WIh42BfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a5cd76d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = preprocess(frame)\n",
    "print (frame.max(), frame.min(), frame.mean())\n",
    "\n",
    "print (a.shape, a.dtype, np.max(a), np.min(a), np.mean(a))\n",
    "plt.imshow(np.squeeze(a))\n",
    "# plt.imshow(to_grayscale(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[84*84*4]) # 84 x 84 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addToHistory(his, s):\n",
    "    his.pop(0)\n",
    "    his.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def his2np(his):\n",
    "    return np.concatenate(tuple(his), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state2input(his, s):\n",
    "    addToHistory(his, preprocess(s))\n",
    "    return his2np(his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n",
      "(28224,)\n",
      "(28224,)\n"
     ]
    }
   ],
   "source": [
    "state_history = []\n",
    "s = env.reset()\n",
    "for idx in range(4):\n",
    "    state_history.append(preprocess(s))\n",
    "print (s.shape)\n",
    "s = state2input(state_history, s)\n",
    "s = processState(s)\n",
    "print (s.shape)\n",
    "s = env.reset()\n",
    "s = state2input(state_history, s)\n",
    "s = processState(s)\n",
    "print (s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        #We use slim.conv2d to set up our network \n",
    "        self.scalarInput =  tf.placeholder(shape=[None,84*84*4],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,4])\n",
    "#         self.conv1 = slim.conv2d( \\\n",
    "#             inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "#         self.conv2 = slim.conv2d( \\\n",
    "#             inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "#         self.conv3 = slim.conv2d( \\\n",
    "#             inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "#         self.conv4 = slim.conv2d( \\\n",
    "#             inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO: Implement Dueling DQN                                                  #\n",
    "        # We take the output from the final convolutional layer i.e. self.conv4 and    #\n",
    "        # split it into separate advantage and value streams.                          #\n",
    "        # Outout: self.Advantage, self.Value                                           #\n",
    "        # Hint: Refer to Fig.1 in [Dueling DQN](https://arxiv.org/pdf/1511.06581.pdf)  #\n",
    "        #       In implementation, use tf.split to split into two branches. You may    #\n",
    "        #       use xavier_initializer for initializing the two additional linear      #\n",
    "        #       layers.                                                                # \n",
    "        ################################################################################\n",
    "        pass\n",
    "        init = tf.contrib.layers.xavier_initializer()\n",
    "        V_split, A_split = tf.split(self.conv4, 2, 3)\n",
    "#         V_split = tf.reshape(V_split, [-1, h_size])\n",
    "#         A_split = tf.reshape(A_split, [-1, h_size])\n",
    "        V_split = slim.flatten(V_split)\n",
    "        A_split = slim.flatten(A_split)\n",
    "        self.Value = tf.layers.dense(V_split, 1, kernel_initializer=init)\n",
    "        self.Advantage = tf.layers.dense(A_split, env.action_space.n, kernel_initializer=init)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        #Then combine them together to get our final Q-values. \n",
    "        #Please refer to Equation (9) in [Dueling DQN](https://arxiv.org/pdf/1511.06581.pdf)\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.action_space.n,dtype=tf.float32)\n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Obtain the loss (self.loss) by taking the sum of squares difference          #\n",
    "        # between the target and prediction Q values.                                  #\n",
    "        ################################################################################\n",
    "        pass\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        self.loss = tf.reduce_sum(tf.square(self.Q-self.targetQ))\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 200 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 500 #The max allowed length of our episode.\n",
    "load_model = True #Whether to load a saved model.\n",
    "path = \"./dqn_breakout2\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "INFO:tensorflow:Restoring parameters from ./dqn_breakout2/model-5499.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dqn_breakout2/model-5499.ckpt\n",
      "[2017-11-30 02:46:01,786] Restoring parameters from ./dqn_breakout2/model-5499.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "Episode 9 reward: 1.3\n",
      "Episode 19 reward: 1.1\n",
      "Episode 29 reward: 0.9\n",
      "Episode 39 reward: 1.7\n",
      "Episode 49 reward: 0.5\n",
      "Episode 59 reward: 1.7\n",
      "Episode 69 reward: 2.0\n",
      "Episode 79 reward: 6.2\n",
      "Episode 89 reward: 30.8\n",
      "Episode 99 reward: 31.4\n",
      "Episode 109 reward: 88.0\n",
      "Episode 119 reward: 69.1\n",
      "Episode 129 reward: 40.2\n",
      "Episode 139 reward: 41.7\n",
      "Episode 149 reward: 41.0\n",
      "Episode 159 reward: 69.9\n",
      "Episode 169 reward: 39.7\n",
      "Episode 179 reward: 51.6\n",
      "Episode 189 reward: 44.3\n",
      "Episode 199 reward: 41.0\n",
      "Mean reward per episode: 30.205\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        state_history = []\n",
    "        for idx in range(4):\n",
    "            state_history.append(preprocess(s))\n",
    "        s = state2input(state_history, s)\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "#         while j < max_epLength: #If the agent takes longer than 50 moves to reach either of the blocks, end the trial.\n",
    "        while True:\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            total_steps += 1\n",
    "            \n",
    "            ################################################################################\n",
    "            # TODO: Save the experience to our episode buffer.                             #\n",
    "            # You will need to do the following:                                           #\n",
    "            # (1) Get new state s1 (resized), reward r and done d from a                   #\n",
    "            # (2) Add experience to episode buffer. Hint: experience includes              #\n",
    "            #     s, a, r, s1 and d.                                                       #\n",
    "            ################################################################################\n",
    "            pass\n",
    "#             r = 0\n",
    "#             d = False\n",
    "#             for idx in range(4):\n",
    "#                 _s1, _r, _d, _ = env.step(a)\n",
    "#                 s1 = state2input(state_history, _s1)\n",
    "#                 r += _r\n",
    "#                 d = d or _d\n",
    "            s1, _r, d, _ = env.step(a)\n",
    "            s1 = state2input(state_history, s1)\n",
    "            r = transform_reward(_r)\n",
    "            s1 = processState(s1)\n",
    "            episodeBuffer.add(np.reshape(np.array([s, a, r, s1, d]), [1, 5]))\n",
    "            ################################################################################\n",
    "            #                                 END OF YOUR CODE                             #\n",
    "            ##############################################################################\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    \n",
    "                    ################################################################################\n",
    "                    # TODO: Implement Double-DQN                                                   #\n",
    "                    # (1) Get a random batch of experiences via experience_buffer class            #\n",
    "                    #                                                                              #\n",
    "                    # (2) Perform the Double-DQN update to the target Q-values                     #\n",
    "                    #     Hint: Use mainQN and targetQN separately to chose an action and predict  #\n",
    "                    #     the Q-values for that action.                                            #\n",
    "                    #     Then compute targetQ based on Double-DQN equation                        #\n",
    "                    #                                                                              #\n",
    "                    # (3) Update the primary network with our target values                        #\n",
    "                    ################################################################################ \n",
    "                    pass\n",
    "                    exp_batch = myBuffer.sample(batch_size)\n",
    "                    s_batch = np.vstack(exp_batch[:, 0])\n",
    "                    a_batch = exp_batch[:, 1]\n",
    "                    r_batch = exp_batch[:, 2]\n",
    "                    s1_batch = np.vstack(exp_batch[:, 3])\n",
    "                    d_batch = exp_batch[:, 4]\n",
    "#                     print (exp_batch.shape, s_batch.shape, a_batch.shape, r_batch.shape, s1_batch.shape, d_batch.shape)\n",
    "                    mainQN_predict = sess.run(mainQN.predict, feed_dict={mainQN.scalarInput:s1_batch})\n",
    "                    targetQN_Qout = sess.run(targetQN.Qout, feed_dict={targetQN.scalarInput:s1_batch})\n",
    "                    targetQN_Q_value = targetQN_Qout[range(batch_size), mainQN_predict]\n",
    "                    end_mat = -(d_batch-1)\n",
    "                    target_Q_value = r_batch + y*targetQN_Q_value*end_mat\n",
    "                    target_Q_value = r_batch + y*targetQN_Q_value\n",
    "                    sess.run(mainQN.updateModel, feed_dict={mainQN.scalarInput:s_batch,\\\n",
    "                                                           mainQN.targetQ:target_Q_value,\\\n",
    "                                                           mainQN.actions:a_batch})\n",
    "                    ################################################################################\n",
    "                    #                                 END OF YOUR CODE                             #\n",
    "                    ################################################################################\n",
    "                           \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += _r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(\"Episode\",i,\"reward:\",np.mean(rList[-10:]))\n",
    "    saver.save(sess,path+'/model-'+str(i+5500)+'.ckpt')\n",
    "print(\"Mean reward per episode: \" + str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f38fc1096a0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhS4iEiJU6CIiIUKFLiISIlToIiIh4v8BLNahWv9koCgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37d857fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
